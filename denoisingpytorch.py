# -*- coding: utf-8 -*-
"""DenoisingPytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hfY2rdov1avGFcTmyiDfw8AWUVX683cr
"""

!nvidia-smi

# import libs
import numpy as np
from keras.datasets import mnist
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPool2D, Dense, UpSampling2D, BatchNormalization
from keras.callbacks import ModelCheckpoint

import tensorflow as tf
devices = tf.config.experimental.list_physical_devices("GPU")
print(devices)
tf.config.experimental.set_memory_growth(devices[0], enable = True)



"""Loading nd Cropping the images to avoid black edges due to rotation in the augmented data"""

# cropped images
import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split

def crop_images(images, crop_percent):
    cropped_images = []
    for img in images:
        height, width = img.shape[:2]
        crop_pixels = int(min(height, width) * crop_percent / 100)

        cropped_img = img[crop_pixels:height-crop_pixels, crop_pixels:width-crop_pixels]
        cropped_images.append(cropped_img)
    return cropped_images

def load_images_from_folder(folder_path):
    images = []
    for filename in os.listdir(folder_path):
        img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (700, 700), fx=1, fy=1)
        if img is not None:
            images.append(img)
    return images

# Load images from folder
folder_path = "/content/sample_data/images"
images = load_images_from_folder(folder_path)

# Crop images to avoid cutting off 15 percent of each side
images = crop_images(images, crop_percent=5)

# Split data into train and test sets
X_train, X_temp = train_test_split(images, test_size=0.1, random_state=42)  # Adjust the size accordingly

# Now split the temporary set into validation and testing sets
X_val, X_test = train_test_split(X_temp, test_size=0.3, random_state=42)  # Splits the temporary set equally

# Convert lists to numpy arrays
X_train = np.array(X_train)
X_val = np.array(X_val)
X_test = np.array(X_test)
# Now, you need to add a channel dimension if they are grayscale images
X_train = X_train[:, np.newaxis, :, :]
X_val = X_val[:, np.newaxis, :, :]
X_test = X_test[:, np.newaxis, :, :]

# Convert numpy arrays to torch tensors (you will do this when creating the dataset for DataLoader)
import torch
X_train = torch.tensor(X_train, dtype=torch.float32)
X_val = torch.tensor(X_val, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32)

from matplotlib import pyplot as plt
fig, axes = plt.subplots(2, 2, figsize=(12, 12))

count = 0
for i in range(2):
    for j in range(2):

        image_to_display = X_train[count][0]
        axes[i, j].imshow(image_to_display, cmap='gray')
        count += 1

plt.show()

"""Normalize"""

X_train = X_train / 255.0
X_test = X_test / 255.0
X_val = X_val / 255.0

"""Add Noise

striped noise one
Generate Random Horizontal Stripes:

Generates random values within a specified range for each row in the image.
Repeats these values across all columns to create horizontal stripes.
Apply Stripes Noise:

Loops through each image in the batch.
Generates a random stripe mask for the image.
Blends the stripe mask with the image using a specified blend factor.
Converts the noisy image back to a tensor and stores it.
for usage, we can apply changes directly to the dataset X-train, X-test, X-val by changing the parameters here , X_train_noise = apply_stripes_noise(X_train, blend_factor=0.4, min_val=0.0, max_val=0.2) this will change the appearence of the noise

Note: the combination of both stripeed noise make a very realistic striped noise observed in STM images
"""

import torch
import numpy as np
import cv2

def generate_random_horizontal_stripes(shape, stripe_height=100, min_val=0.0, max_val=0.2):
    # Generate random stripe values within a specified range
    stripe_mask = torch.rand(shape[0], 1) * (max_val - min_val) + min_val

    # Repeat the stripe values for each pixel in the row
    stripe_mask = stripe_mask.repeat(1, shape[1])

    return stripe_mask

def apply_stripes_noise(images, stripe_height=100, blend_factor=0.1, min_val=0.0, max_val=0.2):
    noisy_images = torch.zeros_like(images)
    for i in range(len(images)):
        image_tensor = images[i]  # Extract tensor from the batch
        image_shape = image_tensor.shape[1:]  # Assuming dataset is shaped as [batch, channels, height, width]

        # Generate random stripe mask
        stripe_mask = generate_random_horizontal_stripes(image_shape, stripe_height, min_val, max_val)

        # Blend the stripe mask with the image
        noisy_image = cv2.addWeighted(image_tensor[0].numpy(), 1.0 - blend_factor, stripe_mask.numpy().astype(np.float32), blend_factor, 0)

        # Convert noisy image back to tensor
        noisy_image_tensor = torch.from_numpy(noisy_image).unsqueeze(0)

        # Assign the noisy image tensor to the corresponding position in the output tensor
        noisy_images[i] = noisy_image_tensor

    return noisy_images

# Example usage:
#  X_train, X_test, and X_val are datasets shaped as [batch, channels, height, width]
X_train_noise = apply_stripes_noise(X_train, blend_factor=0.07, min_val=0.0, max_val=0.9)
X_test_noise = apply_stripes_noise(X_test, blend_factor=0.07, min_val=0.0, max_val=0.9)
X_val_noise = apply_stripes_noise(X_val, blend_factor=0.07, min_val=0.0, max_val=0.9)

# Displaying the noisy images from X_train_noise
from matplotlib import pyplot as plt

# Number of images to display
num_images = 2

fig, axes = plt.subplots(1, num_images, figsize=(12, 12))
for i in range(num_images):
    axes[i].imshow(X_train_noise[i][0], cmap='gray')
    axes[i].set_title(f'Noisy Image {i+1}')
    axes[i].axis('off')

plt.show()

"""striped noise two
Generate Random Horizontal Stripes:

Creates a mask with specified number of horizontal stripes of random width and position.
Apply Stripes Noise:

Iterates over a batch of images.
Generates and applies random horizontal stripes to each image.
Blends the stripes with random noise and the original image.
"""

import numpy as np

def generate_random_horizontal_stripes(shape, num_stripes=10, max_width=1):
    mask = np.zeros(shape)
    for _ in range(num_stripes):
        start_row = np.random.randint(shape[0])
        stripe_width = np.random.randint(1, max_width + 1)
        mask[start_row:start_row + stripe_width, :] = 1
    return mask
def apply_stripes_noise(images, num_stripes=10, max_width=1):
    noised_images = np.zeros_like(images)
    for i in range(len(images)):
        # Generate mask for each image
        mask = generate_random_horizontal_stripes(images[i][0].shape, num_stripes, max_width)  # [0] for the first channel
        # Apply mask: where mask is 1, add random noise; where mask is 0, keep the original image
        random_noise = np.random.rand(*images[i][0].shape)
        noised_image = images[i][0] * (1 - mask) + random_noise * mask
        noised_images[i][0] = noised_image  # Put the modified image back into the right slot
    return noised_images

# Assuming X_train and X_test are your datasets shaped as [batch, 1, height, width]
X_train_noise1 = apply_stripes_noise(X_train_noise)
X_test_noise1 = apply_stripes_noise(X_test_noise)
X_val_noise1 = apply_stripes_noise(X_val_noise)
from matplotlib import pyplot as plt

fig, axes = plt.subplots(2, 2, figsize=(12, 12))
count = 0
for i in range(2):
    for j in range(2):
        # Display the first channel of the noised images
        axes[i, j].imshow(X_train_noise1[count][0], cmap='gray')
        count += 1

plt.show()

X_train.shape

print("Original size of X_train:", X_train.size)

"""Reshape"""

X_train = X_train.reshape(X_train.shape[0], 1,630 ,630)
X_test = X_test.reshape(X_test.shape[0], 1, 630,630)

X_train_noise1 = X_train_noise1.reshape(X_train_noise1.shape[0],1, 630,630)
X_test_noise1 = X_test_noise1.reshape(X_test_noise1.shape[0],1, 630,630)
X_val_noise1 = X_val_noise1.reshape(X_val_noise1.shape[0],1, 630,630)

X_train.shape, X_train_noise1.shape



import torch
import torch.nn as nn

class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # `nn.Conv2d` assumes channel first
            nn.ReLU(True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(True),
            nn.MaxPool2d(2, 2)
        )

        self.decoder = nn.Sequential(
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(True),
            nn.Upsample(scale_factor=2, mode='nearest'),
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(True),
            nn.Upsample(scale_factor=2, mode='nearest'),
            nn.Conv2d(32, 1, kernel_size=3, padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import matplotlib.pyplot as plt
import numpy as np

# Convert numpy arrays to torch tensors
X_train_noise1_torch = torch.tensor(X_train_noise1, dtype=torch.float32)
X_train_torch = torch.tensor(X_train, dtype=torch.float32)
X_test_noise1_torch = torch.tensor(X_test_noise1, dtype=torch.float32)
X_test_torch = torch.tensor(X_test, dtype=torch.float32)
X_val_noise1_torch = torch.tensor(X_val_noise1, dtype=torch.float32)
X_val_torch = torch.tensor(X_val, dtype=torch.float32)
# Create datasets and dataloaders
train_dataset = TensorDataset(X_train_noise1_torch, X_train_torch)
train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)

# Create a validation dataset
test_dataset = TensorDataset(X_test_noise1_torch, X_test_torch)

# Create a validation dataloader
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)

# Create a validation dataset
val_dataset = TensorDataset(X_val_noise1_torch, X_val_torch)

# Create a validation dataloader
val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)

# Create model, loss function, and optimizer
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = optim
# Create model, loss function, and optimizer
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Setup device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

"""Training"""

import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np

def train_model(num_epochs):
    best_loss = np.inf
    train_losses = []
    val_losses = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()

            outputs = model(inputs)

            # Resize labels to match the output size
            labels_resized = F.interpolate(labels, size=outputs.shape[2:])

            loss = criterion(outputs, labels_resized)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)
        train_losses.append(epoch_loss)

        # Validation loss
        model.eval()
        with torch.no_grad():
            val_loss = 0.0
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                labels_resized = F.interpolate(labels, size=outputs.shape[2:])
                loss = criterion(outputs, labels_resized)
                val_loss += loss.item() * inputs.size(0)

        epoch_val_loss = val_loss / len(val_loader.dataset)
        val_losses.append(epoch_val_loss)

        # Save the best model
        if epoch_val_loss < best_loss:
            best_loss = epoch_val_loss
            torch.save(model.state_dict(), 'denoising_model16-9240.pth')

        print(f'Epoch {epoch+1} Train Loss: {epoch_loss:.4f} Val Loss: {epoch_val_loss:.4f}')

    # Plot loss
    plt.plot(train_losses, label='Training Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.title('Loss vs. Epoch')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()

train_model(100)

"""Results Visulzation"""

import matplotlib.pyplot as plt

def visualize_results(noisy_images, clean_images, denoised_images, num_examples=2):
    fig, axes = plt.subplots(num_examples, 3, figsize=(9, num_examples * 3))
    for i in range(num_examples):
        # Display True Image
        ax = axes[i, 1]
        ax.imshow(clean_images[i][0], cmap='gray')  # Assuming channel-first format
        ax.set_title("Clean Image")
        ax.axis('off')

        # Display Noisy Image
        ax = axes[i, 0]
        ax.imshow(noisy_images[i][0], cmap='gray')  # Assuming channel-first format
        ax.set_title("Noisy Image")
        ax.axis('off')



        # Display Denoised Image
        ax = axes[i, 2]
        ax.imshow(denoised_images[i][0], cmap='gray')  # Assuming channel-first format
        ax.set_title("Denoised Image")
        ax.axis('off')

    plt.show()

# Prepare to visualize results
# Let's load some test data
test_loader_iter = iter(test_loader)
inputs, labels = next(test_loader_iter)
inputs, labels = inputs.to(device), labels.to(device)

# Get model predictions
model.eval()
with torch.no_grad():
    outputs = model(inputs)

# Convert tensors to numpy arrays for visualization
clean_images_np = labels.cpu().numpy()
noisy_images_np = inputs.cpu().numpy()
denoised_images_np = outputs.cpu().numpy()

# Visualize results
visualize_results( noisy_images_np,clean_images_np,denoised_images_np)

"""Calculation of the mean square error"""

from sklearn.metrics import mean_squared_error
def calculate_psnr(img1, img2):

    mse = mean_squared_error(img1.flatten(), img2.flatten())
    if mse == 0:
        return float('inf')
    return 20 * np.log10(255.0 / np.sqrt(mse))

# Recalculate PSNR with flattened images
psnr_values = [calculate_psnr(clean, denoised) for clean, denoised in zip(clean_images_np, denoised_images_np)]
average_psnr = sum(psnr_values) / len(psnr_values)

print("Average PSNR:", average_psnr)

"""visualization of dnoised images not seen by the model"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from torchvision.io import read_image
from torchvision.utils import save_image
import matplotlib.pyplot as plt

class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.ReLU(True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(True),
            nn.MaxPool2d(2, 2)
        )
        self.decoder = nn.Sequential(
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(True),
            nn.Upsample(scale_factor=2, mode='nearest'),
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(True),
            nn.Upsample(scale_factor=2, mode='nearest'),
            nn.Conv2d(32, 1, kernel_size=3, padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Path to the model
path = '/content/sample_data/denoising_model9.pth'

# Instantiate and load the model
model = Autoencoder()
model.load_state_dict(torch.load(path))
model.eval()

# Function to load and preprocess the image
def preprocess_image(file_path):
    image = read_image(file_path)
    if image.shape[0] > 1:
        image = image[0].unsqueeze(0)

    transform = transforms.Compose([
        transforms.Resize((700, 700)),
        transforms.ConvertImageDtype(torch.float32),
        transforms.Normalize(mean=[0.3], std=[0.7])
    ])

    return transform(image).unsqueeze(0)

# Load and preprocess your image
img = preprocess_image("/content/sample_data/TiSe2_175k_0043.jpg")

# Predict the denoised image
with torch.no_grad():
    denoised_img = model(img)

# Convert back to a displayable format
denoised_img = denoised_img.squeeze(0) * 0.5 + 0.5  # Reverse normalization
denoised_img = denoised_img.mul(255).clamp(0, 255).type(torch.uint8)  # Scale to [0, 255]

# Save the denoised image
pil_image = transforms.ToPILImage()(denoised_img.squeeze(0))
pil_image.save('/content/sample_data/denoised_image2.jpg')

# Function to calculate PSNR
def calculate_psnr(original, denoised):
    mse = F.mse_loss(original.float(), denoised.float())
    if mse == 0:
        return float('inf')
    max_pixel_value = 255.0
    psnr = 10 * torch.log10((max_pixel_value ** 2) / mse)
    return psnr.item()

# Load original and denoised images for PSNR calculation
def load_grayscale_image(file_path):
    image = read_image(file_path).float()
    if image.shape[0] > 1:
        image = image[0].unsqueeze(0)
    return image

original_img = load_grayscale_image("/content/sample_data/denoised_image2.jpg")
denoised_img = load_grayscale_image("/content/sample_data/TiSe2_175k_0043.jpg")

# Ensure dimensions match
if original_img.shape != denoised_img.shape:
    transform = transforms.Resize(original_img.shape[1:])
    denoised_img = transform(denoised_img)

# Calculate and print PSNR
psnr_value = calculate_psnr(original_img, denoised_img)
print(f"PSNR: {psnr_value} dB")



from google.colab import drive
drive.mount('/content/drive')

